---
title: "Conditional Inference Trees"
description: "Supervised learning classifications using the R package **partykit** conditional inference trees"
author: "Oscar Cardec"
date: "10/22/2020"
categories: [CTREE, Decision Tree, Classification]
image: ctg.jpeg
page-layout: full
bibliography: references.bib
---

### Introduction

Cardiotocograms, also known as CTGs, have been instrumental within clinical medicine for a long time. Obstetricians use these measurements and classifications to obtain detailed information and intelligence about newborns and their mother prior and during labor. In 2018, an article presented through the Journal of Clinical Medicine detailed the practicality of CTG. The same article noted that interpretations of these censorial readings is mainly attributed to the observer; which creates challenges of consistency of interpretations and defies the human naked- eye. Questions like what happens if/when the interpreter misses a key detail, or what could be the meaning of a combination of diagnostic signals, furthermore, what time-sensitive conditions may these measurements expose, requiring immediate actions? These are few examples of concerns posed by the continuous practice of merely optical assessments of a df. [@zhao2018]

The following exploration presents an assessment of CTGs using the conditional inference tree (ctree) model. The same shows how the algorithm expedites and enhances the interpretation of CTG readings while appraising multiple fetal readings simultaneously. Moreover, the study aims to identify potential hidden patters which may require further attention.

### Data

The analyzed data comes for the UCI Machine Learning Repository[@d.campos2000a], and it consists of measurements of fetal heart rate (FHR) and other important characteristics as identified and recorded within each cardiotocograms. Ultimately, all CTGs were classified by three subject matter experts, and under unanimity, assigned with response-labels based on the fetal state and/or morphological detected patterns. The following is a list of the variables meaning according to the UCI repository:

-   LB - FHR baseline (beats per minute)
-   AC - \# of accelerations per second
-   FM - \# of fetal movements per second
-   UC - \# of uterine contractions per second
-   DL - \# of light decelerations per second
-   DS - \# of severe decelerations per second
-   DP - \# of prolonged decelerations per second
-   ASTV - percentage of time with abnormal short term variability
-   MSTV - mean value of short term variability
-   ALTV - percentage of time with abnormal long term variability
-   MLTV - mean value of long term variability Width - width of FHR histogram
-   Min - minimum of FHR histogram
-   Max - Maximum of FHR histogram
-   Nmax - \# of histogram peaks
-   Nzeros - \# of histogram zeros
-   Mode - histogram mode
-   Mean - histogram mean
-   Median - histogram median
-   Variance - histogram variance
-   Tendency - histogram tendency
-   CLASS - FHR pattern class code (1 to 10)
-   NSP - fetal state class code (N=normal; S=suspect; P=pathologic)

### EDA

```{r Requirements}
#| echo: false
#| warning: false

library("tidyverse")
library("party")
library("partykit")
library("graphics")
library("devtools")
library("hrbrthemes")
library("caret")
library("rmarkdown")
library("quarto")
library("stats")
```

During exploratory data analysis the data is confirmed as a combination of 2126 observations and 23 variables. The following is a preview of the first six observations after been ingested as *as_tibble*.

```{r Preview}
#| expandable: true
df<-as_tibble(read.csv(file="cardiotocography.csv", head=TRUE, sep=",", as.is=FALSE))
print(df, n=6)
```

The following code chunks portray a basic assessment of specific attributes and areas of importance such as variability of observations, presence of missing values, mean, standard deviation,

```{r LB-Summary}
# How much variability the main predictor shows? 
lbx <- IQR(df$LB)
summary(df$LB)
```

Note: LB attribute's IQR equals 14, which is significantly small indicating a most values to be clustered around the middle. The following histogram confirms the small IQR.

```{r Hist, fig.height=4,fig.width=8}
hist(df$LB, breaks = 12, main="Histogram of FHR Baseline", xlab="(beats per minute)",
     border="darkblue",col ="lightgrey", labels = F)
```

```{r missing-vals}
# Are there any missing values present?
colSums(is.na(df))
```

```{r t-test}
t.test(df$LB)
```

```{r Variation, fig.height=4,fig.width=8}
#| warning: false
# LB stats
m<-mean(df$LB)
std<-sd(df$LB)
upr=m+std
lwr=m-std
lbdf <- data.frame(df,my_x = 0 + rnorm(length(df$LB),
        mean=m, sd=std),my_y = 0 + rnorm(length(df$LB), mean=m, sd=std))
# LB Variation
print(pltlb <- ggplot(lbdf, xlab = F, aes(x=(my_x), y=my_y)) + 
        geom_line(col="grey51",linemitre=1) +
        geom_smooth(method=lm , color="blue", lty=3, fill="light blue", se=T) +
        labs(x=NULL, y="BPM", title="FHR LB Variation\nIn Relation To The Mean")+
        theme_ipsum())
```

```{r stdev, fig.height=4,fig.width=8}
# very first graph representation with manual boundary calculations
upr2=m+(std*2)
lwr2=m-(std*2)
# Plot LB distribution boundaries 
plot.new()
plot(df$LB, type="l", col="grey51", ylab="LB", main="1 & 2 Standard Deviations")
abline(h = m, col = "blue")
abline(h = upr, col = "orange", lty=2)
abline(h = lwr, col = "orange", lty=2)
abline(h = upr2, col = "red", lty=2)
abline(h = lwr2, col = "red", lty=2)
text(-65,134, "mean:133.30", col = "blue", adj = c(0, -.1))
text(-65,upr, round(upr, 2), col = "black", adj = c(0, -.1))
text(-65,lwr, round(lwr, 2), col = "black", adj = c(0, -.1))
text(-65,upr2, round(upr2, 2), col = "black", adj = c(0, -.1))
text(-65,lwr2, round(lwr2, 2), col = "black", adj = c(0, -.1))
# LB Observations higher than 2-s.d.
 lba<-(sum(df$LB >152.99)) #39
# LB Observations lower than 2-s.d.
 lbb<-(sum(df$LB <113.62)) #44
 lba+lbb #=83 obs outside of 2-s.d.
sum(between(df$LB, 113.62, 152.99))/nrow(df) # of obs within 2-s.d.

```

```{r factorizeNSP}
# Exclude non-original measurements, rename targeted values
df[12:22] <- NULL
df$NSP<-as.numeric(df$NSP)
# enumeration of labels with the factor function
df$NSP<-factor(df$NSP, levels= 1:3, labels = c("Normal","Suspect", "Pathologic"))

```

```{r nsp-distro, fig.height=5,fig.width=10}
# Visualization of original NSP
plot(df$NSP, main="Original NSP Distribution",
     xlab="Fetal State Classification", 
     ylab="Frequency", col=c(3, 7, 2))
text(df$NSP, labels=as.character(tabulate(df$NSP)), adj=3, pos=3)
```

```{r distributions, fig.height=8,fig.width=12}
#| warning: false

# additional way to preview distribution of attributes
# distributions preview
df[,1:12] %>%
  gather() %>%
  ggplot(aes(value)) +
  theme_light() + labs( title="FHR Measurement Distributions")+
  theme(axis.text.x = element_text(angle=90)) +
  facet_wrap(~ key, scales = "free", shrink = TRUE) +
  geom_bar(mapping = aes(value),
           color="darkblue", fill="lightgrey")
```

In progress ...

```{r summary, fig.height=7,fig.width=10}
# Summary of DF after encoding the label vector as numbers. 
summary(df)
```

```{r train-test}
# split the data into a training and test sets
set.seed(1234)
ind <- sample(2, nrow(df), replace = T, prob = c(0.70, 0.30))
train.data <- df[ind == 1, ]
test.data <- df[ind == 2, ]

#run the method on a training data
myFormula<-NSP~.
model <- ctree(myFormula, data = train.data)
```

```{r model}
# output the tree structure
# print(model)
model[4]
```

```{r model-treeviz, fig.height=10,fig.width=12}
#8. visualize the tree
# plot(model, main="Cardiotocography Data\n Conditional Inference Tree\n'Extended'",
#       type="simple",ep_args = list(justmin = 8), drop_terminal = F, 
#      gp = gpar(fontsize = 9), margins = c(4,4, 4, 4))

plot(model, type="extended", ep_args = list(justmin =8), drop_terminal=F, tnex=1.5, 
     gp=gpar(fontsize = 8, col="dark blue"),
     inner_panel = node_inner(model, fill=c("light grey","cyan"), pval=T), 
     terminal_panel=node_barplot(model, fill=c(3,7,2), beside=T, ymax=1, rot = 45, 
     just = c(.95,.5), ylines=F, widths = 1, gap=0.05, reverse=F, id=T), 
     margins = c(3,0, 3, 0),
     main ="Cardiotocography Data\n Conditional Inference Tree\n'Extended'")
```

```{r conf-matrix}
#9. Confusion matrix
table(predict(model), train.data$NSP, dnn=c("PREDICTED", "ACTUAL"))
# predicted classification accuracy with training data
sum(predict(model) == train.data$NSP)/length(train.data$NSP)
prop.table(table(predict(model), train.data$NSP, dnn=c("PREDICTED", "ACTUAL")))
```

```{r model2}
#10. Evaluate the model on a test data
model2 <- ctree(myFormula, data = test.data)
model2[4]
```

```{r model2treeviz, fig.height=10,fig.width=12}
# plot(model2, main="Cardiotocography Data\n Simple Conditional Inference Tree\nby ocardec",
#      type="simple",ep_args = list(justmin = 10), drop_terminal = F, gp = gpar(fontsize = 12))

plot(model2, ep_args = list(justmin = 8), type="extended", drop_terminal = F, 
     tnex=1, gp= gpar(fontsize = 8, col="dark blue"), 
     inner_panel = node_inner (model2, fill=c("lightgrey","yellow"), pval=T, id=T),
     terminal_panel=node_barplot(model2, col="black", fill=c(3,7,2, 0.3), beside=T, 
     ymax=1, rot = 45, just = c("right", "top"), ylines=F, 
     widths=1, gap=0.1, reverse=F, id=F), margins = c(3, 0, 3, 0), 
     main="Cardiotocography Data\n Extended Conditional Inference Tree\nby ocardec")
```

```{r conf-matrix2}
# Confusion matrix and stats
testPred2 <- predict(model2, newdata = test.data, method="NSP")
confusionMatrix(testPred2, test.data$NSP)
```
