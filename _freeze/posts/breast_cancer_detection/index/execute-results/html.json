{
  "hash": "5a7541a62fcaf673131870a640969bcf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Cancerous Cells Classification - Neural Network\"\ndescription: \"Malignant cells classification across digitized images of fine needle aspirate (FNA) of a breast mass 3-dimensional fragmentated samples\"\nauthor: \"Oscar Cardec\"\ndate: \"06/21/2020\"\ncategories: [neural network, classification, pca, ctree, rocr, splom]\nimage: img/cyber_ribbon.jpeg\npage-layout: full\nfreeze: true\ncode-block-bg: true\ncode-block-border-left: \"#31BAE9\"\nbibliography: references.bib\neditor_options: \n  chunk_output_type: inline\n---\n\n\n### Introduction\n\nBreast cancer is “the most common cause of cancer deaths among women worldwide”. In the United States, breast cancer is second to lung cancer related deaths, making it a national health critical issue. Statistical facts show breast cancer as the most frequently diagnosed cancer in women in 140 out of 184 countries. Key to survival and remission of breast cancer is closely linked with early detection and intervention.[@henderson2015].\n\nEarly signs of irregular cells growth are detected by sampling and analyzing nuclear changes and parameter using diagnostic tools. The results of these nuclear morphometry tests are evaluated for structural deviations, which are representative of cancer diagnosis.[@narasimha2013] Now, considering the significance in accuracy of these evaluations, one may question how the medical industry uses machine learning models like neural networks to augment diagnosis and judgement of such vital medical assessments.\n\nThe following is post-study report of numerous breast cancer preventive screenings, scrutinizing cell nuclei parameters in order to classify the specimens as either malignant or benign. The data have been previously categorized, thus, the intent here is to employ a neural network methodology to replicate this categorization and measure the algorithm’s effectiveness supporting medical professionals in the identification and early detection of breast carcinoma.\n\n![](img/bcancerdetection.jpeg){fig-align=\"center\" width=\"300\"}\n\n\n\n\n\n### Data\n\nThe employed data, **Breast Cancer Wisconsin - Diagnostic**,comes from the UCI Machine Learning Repository. The multivariate set contains 569 instances and 32 attributes as described bellow. As previously stated, the data set features quantitative observations representative of the images obtained by means of a fine needle aspirate (FNA). These digitized samples were studied, measured and recorded, ultimately enabling the classification of every instance as malignant or benign. Essentially, there is a total of 10 real-value features per cell, however, given the 3-dimensional fragmentation of each cell sampling, it produces a total of 30 observations across 3 planes.[@williamwolberg1993]\n\n-   Variables list across each plane\n    -   1 - **`ID Name`** :: Identification number of the sample\n\n    -   2 - **`Diagnosis`** :: Dependable variable label. M = Malignant, B = Benignant\n\n    -   3 - Feature_1 **`Radius`** :: Mean of distances from center to points on the perimeter\n\n    -   4 - Feature_2 **`Texture`** :: Standard deviation of gray-scale values\n\n    -   5 - Feature_3 **`Perimeter`** ::\n\n    -   6 - Feature_4 **`Area`** ::\n\n    -   7 - Feature_5 **`Smoothness`** :: Local variation in radius lengths\n\n    -   8 - Feature_6 **`Compactness`** :: Perimeter\\^2 / Area - 1.0\n\n    -   9 - Feature_7 **`Concavity`** :: Severity of concave portions of the contour\n\n    -   10 - Feature_8 **`Concave Points`** :: Number of concave portions of the contour\n\n    -   11 - Feature_9 `Symmetry` ::\n\n    -   12 - Feature_10 `Fractal Dimension` :: Coastline approximation - 1\n\n\n::: {.cell}\n\n:::\n\n\n### Exploratory Data Analysis\n\n> Basic descriptive statistics of the data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sample of statistical summary - Plane 1\ndescribe(df[1:10], interp = TRUE, ranges = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           vars   n   mean     sd skew kurtosis    se\nDiagnosis*    1 569   1.37   0.48 0.53    -1.73  0.02\nFeature_1     2 569  14.13   3.52 0.94     0.81  0.15\nFeature_2     3 569  19.29   4.30 0.65     0.73  0.18\nFeature_3     4 569  91.97  24.30 0.99     0.94  1.02\nFeature_4     5 569 654.89 351.91 1.64     3.59 14.75\nFeature_5     6 569   0.10   0.01 0.45     0.82  0.00\nFeature_6     7 569   0.10   0.05 1.18     1.61  0.00\nFeature_7     8 569   0.09   0.08 1.39     1.95  0.00\nFeature_8     9 569   0.05   0.04 1.17     1.03  0.00\nFeature_9    10 569   0.18   0.03 0.72     1.25  0.00\n```\n\n\n:::\n:::\n\n\n> Density exploration of diagnosis across four specific variables: `radius`, `area`, `texture`, and `concave`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Explore density \ng1 <- ggplot(data = df)+\n  theme_minimal()+\n  geom_density(mapping = aes(Feature_1,  fill = Diagnosis), col=\"darkgrey\", show.legend = FALSE, alpha=0.5)+ \n  labs(title = \"Density of Diagnosis per Attribute | Red = Benignant, Blue = Malignant\", y = \" \", x = \"Radius\")\n\ng2 <- ggplot(data = df)+\n  theme_minimal()+\n  geom_density(mapping = aes(Feature_2, fill = Diagnosis), col=\"darkgrey\", show.legend = FALSE, alpha=0.5)+ \n  labs(title = \"\", y = \" \", x = \"Texture\")\n\ng3 <- ggplot(data = df)+\n  theme_minimal()+\n  geom_density(mapping = aes(Feature_4, fill = Diagnosis), col=\"darkgrey\", show.legend = FALSE, alpha=0.5)+ \n  labs(title = \"\", y = \" \", x = \"Area\")\n\ng4 <- ggplot(data = df)+\n  theme_minimal()+\n  geom_density(mapping = aes(Feature_7, fill = Diagnosis), col=\"darkgrey\", show.legend = FALSE, alpha=0.5)+ \n  labs(title = \"\", y = \" \", x = \"Concavity\")\n\ngrid.arrange(arrangeGrob(g1,  g2,  g3, g4),  nrow=1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/density_displays-1.png){width=960}\n:::\n:::\n\n\nKey insight, these density plots are useful alternatives illustrating continuous data point. The selected variables are just examples of what can swiftly be illustrated to identify potential relationships between the feature and dependent variable.\n\n### Pre-Visualization of Data\n\nHere I use a conditional inference tree to estimate relationships across the data and how its recursively partitioned by the algorithm criteria. The main intent here is to have an idea on what to expect regarding the classification of this data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# mutate diagnosis character to numeric\ndf <- df |> \n  mutate(Diagnosis = ifelse(Diagnosis == \"M\", 1, 0)) \n\n# CTREE model and plot\nmodel <- ctree(Diagnosis ~., data = df)\nplot(model, type=\"extended\", ep_args = list(justmin=8), \n     main=\"Breast Cancer | Preliminary Analysis\",\n     drop_terminal=FALSE, tnex=1.5, \n     gp = gpar(fontsize = 12, col=\"darkblue\"),\n     inner_panel = node_inner(model, fill=c(\"white\",\"green\"), pval=TRUE), \n     terminal_panel=node_barplot(model, fill=rev(c(\"darkred\",\"lightgrey\")), beside=TRUE, ymax=1.0, \n                                 just = c(0.95,0.5), ylines=TRUE, widths = 1.0, gap=0.05, \n                                 reverse=FALSE, id=TRUE)\n     )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/pre_viz-1.png){width=1152}\n:::\n:::\n\n\n#### Scatterplot of Matrix (SPLOM)\n\nThis scatterplox matrix portraits immediate correlation between the included variables and possible multicollinearity among these. The selected features were limited to the first plane only (items 1 to 10). The other two planes include similar features. My immediate take was to consider a method for dimensionality reduction even when considering a neural network classification model.\n\n<br/>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot Plane I\nclrs <- c(\"darkred\", \"lightgrey\")\n\npairs(df[1:11], fill=clrs, main = \"Plane I - Matrix of Scatterplots\", \n      cex.main= 2.0, cex.labels = 1.0, lower.panel = NULL, pch = 21, \n      col=\"grey\", bg = clrs [unclass(df$Diagnosis)])\n\npar (xpd = TRUE)\n\nlegend (0.10, 0.01, horiz = TRUE, as.vector(unique(df$Diagnosis)), fill=clrs, bty = \"n\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/splom-1.png){width=1152}\n:::\n:::\n\n\n### Dimensionality Reduction\n\nAs defined, the purpose of dimensionality reduction is to find a method that can represents a given data set using a smaller number of features but still containing the original data's properties. I know there are different methods to accomplish this, case in point, LDA, PCa, t-SNE, K-NN, UMAP, etc., but I ultimately decided to use PCA for feature extraction. The following steps illustrate how the method identifies eigenvector of largest eigenvalues of across the covariance matrix. As a result, I create a sub-set of the data using these variables with maximum influence on variance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# pca of original data\nres.pca <- PCA(df, scale.unit = TRUE, graph = FALSE, ncp = 4)\neig.val <- get_eigenvalue(res.pca)\nvar <- get_pca_var(res.pca)\n\n# Color by cos2 values: quality on the factor map\nfviz_pca_var(res.pca, col.var = \"contrib\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE \n             )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/pca-1.png){width=672}\n:::\n:::\n\n\n### Sub-selected Features\n\nHere's my source code to create a subset based on the PCA, followed by conditioning the target variable as a factor for down-sampling purposes. The down-sampling approach was ensure an equally number of target outcomes and avoiding any model disposition towards one way or the other. Completed the down-sampling, I scale and centered the data to maximize model performance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# selection of principal components \npdf <- df |> \n  select(Diagnosis, Feature_1, Feature_2, Feature_3, Feature_4, Feature_6, Feature_7, Feature_8,\n         Feature_10, Feature_11, Feature_13, Feature_14, Feature_16, Feature_18, Feature_20,\n         Feature_21, Feature_23, Feature_24, Feature_26, Feature_27, Feature_28,\n         Feature_30\n         )\n\n# mutating as a factor for downsampling \npdf <- pdf |> \n  dplyr::mutate(Diagnosis = as.factor(Diagnosis))\n\n# class definition\ntarget <- \"Diagnosis\"\n\n# downsampling\nset.seed(12345)\ndownsampled_df <- downSample(x = pdf[, colnames(pdf) != target], y = pdf[[target]])\ndownsampled_df <- cbind(downsampled_df, downsampled_df$Class)\ncolnames(downsampled_df)[ncol(downsampled_df)] <- target\n\n# subset, mutate, and scale\ndf2 <- pdf \ndf2 <- df2 |> \n  mutate(Diagnosis = as.character(Diagnosis),\n         Diagnosis = as.numeric(Diagnosis))\ndf2[, -1] <- scale(df2[, -1])\n```\n:::\n\n\n> Final summary statistics across the data set.\n\n<br/>\n\n\n::: {.cell}\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |df2  |\n|Number of rows           |569  |\n|Number of columns        |22   |\n|_______________________  |     |\n|Column type frequency:   |     |\n|numeric                  |22   |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate| mean|   sd|    p0|   p25|   p50|  p75|  p100|hist  |\n|:-------------|---------:|-------------:|----:|----:|-----:|-----:|-----:|----:|-----:|:-----|\n|Diagnosis     |         0|             1| 0.37| 0.48|  0.00|  0.00|  0.00| 1.00|  1.00|▇▁▁▁▅ |\n|Feature_1     |         0|             1| 0.00| 1.00| -2.03| -0.69| -0.21| 0.47|  3.97|▂▇▃▁▁ |\n|Feature_2     |         0|             1| 0.00| 1.00| -2.23| -0.73| -0.10| 0.58|  4.65|▃▇▃▁▁ |\n|Feature_3     |         0|             1| 0.00| 1.00| -1.98| -0.69| -0.24| 0.50|  3.97|▃▇▃▁▁ |\n|Feature_4     |         0|             1| 0.00| 1.00| -1.45| -0.67| -0.29| 0.36|  5.25|▇▃▂▁▁ |\n|Feature_6     |         0|             1| 0.00| 1.00| -1.61| -0.75| -0.22| 0.49|  4.56|▇▇▂▁▁ |\n|Feature_7     |         0|             1| 0.00| 1.00| -1.11| -0.74| -0.34| 0.53|  4.24|▇▃▂▁▁ |\n|Feature_8     |         0|             1| 0.00| 1.00| -1.26| -0.74| -0.40| 0.65|  3.92|▇▃▂▁▁ |\n|Feature_10    |         0|             1| 0.00| 1.00| -1.82| -0.72| -0.18| 0.47|  4.91|▆▇▂▁▁ |\n|Feature_11    |         0|             1| 0.00| 1.00| -1.06| -0.62| -0.29| 0.27|  8.90|▇▁▁▁▁ |\n|Feature_13    |         0|             1| 0.00| 1.00| -1.04| -0.62| -0.29| 0.24|  9.45|▇▁▁▁▁ |\n|Feature_14    |         0|             1| 0.00| 1.00| -0.74| -0.49| -0.35| 0.11| 11.03|▇▁▁▁▁ |\n|Feature_16    |         0|             1| 0.00| 1.00| -1.30| -0.69| -0.28| 0.39|  6.14|▇▃▁▁▁ |\n|Feature_18    |         0|             1| 0.00| 1.00| -1.91| -0.67| -0.14| 0.47|  6.64|▇▇▁▁▁ |\n|Feature_20    |         0|             1| 0.00| 1.00| -1.10| -0.58| -0.23| 0.29|  9.84|▇▁▁▁▁ |\n|Feature_21    |         0|             1| 0.00| 1.00| -1.73| -0.67| -0.27| 0.52|  4.09|▆▇▃▁▁ |\n|Feature_23    |         0|             1| 0.00| 1.00| -1.69| -0.69| -0.29| 0.54|  4.28|▇▇▃▁▁ |\n|Feature_24    |         0|             1| 0.00| 1.00| -1.22| -0.64| -0.34| 0.36|  5.92|▇▂▁▁▁ |\n|Feature_26    |         0|             1| 0.00| 1.00| -1.44| -0.68| -0.27| 0.54|  5.11|▇▅▁▁▁ |\n|Feature_27    |         0|             1| 0.00| 1.00| -1.30| -0.76| -0.22| 0.53|  4.70|▇▅▂▁▁ |\n|Feature_28    |         0|             1| 0.00| 1.00| -1.74| -0.76| -0.22| 0.71|  2.68|▅▇▅▃▁ |\n|Feature_30    |         0|             1| 0.00| 1.00| -1.60| -0.69| -0.22| 0.45|  6.84|▇▃▁▁▁ |\n\n\n:::\n:::\n\n\n> Visualization of variables as defined by the PCA across the first and second dimensions.\n\n<br/>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# pca of subset data\nres.pca <- PCA(df2, scale.unit = FALSE, graph = FALSE, ncp =4)\neig.val <- get_eigenvalue(res.pca)\nvar <- get_pca_var(res.pca)\n\n# Color by cos2 values: quality on the factor map\nfviz_pca_var(res.pca, col.var = \"contrib\",\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"), \n             repel = TRUE \n             )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/subset_fviz-1.png){width=672}\n:::\n:::\n\n\n### Data Partitioning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345)\n\n# splitting  \nind <- sample(1:3, nrow(df2), replace=TRUE, prob=c(0.50, 0.25, 0.25))\ntrainData <- df2[ind == 1, ]\ntestData <- df2[ind == 2, ]\nxvalData <- df2[ind == 3, ]\n```\n:::\n\n\n### Model Training and Visualization\n\nTraining of the neural network using the R library of `neuralnet`. This poweful algorithm \"is based on the resilient backpropagation without weight backtracking and additionally modifies one learning rate, either the learningrate associated with the smallest absolute gradient (sag) or the smallest learningrate (slr) itself. The learning rates in the grprop algorithm are limited to the boundaries defined in learningrate.limit.\"[@neuralnet]\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# neuralnet \nnn <- neuralnet(Diagnosis ~., data = trainData, hidden = c(3),\n                lifesign = \"minimal\", linear.output = FALSE, likelihood=TRUE\n                # act.fct = \"tanh\", err.fct = \"sse\"\n                )\n\n# plot model\nplot(nn, radius = 0.03, arrow.length = 0.16, intercept = TRUE,\n     intercept.factor = 0.2, information = TRUE, information.pos = 8,\n     col.entry.synapse = \"black\", col.entry = \"maroon4\", line_stag= 0.1,\n     col.hidden = \"darkblue\", col.hidden.synapse = \"dimgrey\",\n     col.out = \"green\", col.out.synapse = \"blue\",\n     col.intercept = \"red\", fontsize = 9, dimension = 2,\n     show.weights = TRUE, rep = \"best\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/nnplot-1.png){width=1152}\n:::\n:::\n\n\n#### Model's Evaluation\n\nObservation & Notes \\| Section **in-progress ...**\n\n-   Approach\n    -   Training\n\n    -   Testing\n\n    -   Cross-validation\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model evaluation\nmypredict <- neuralnet::compute(nn, nn$covariate)$net.result\nmypredict <- apply(mypredict, c(1), round)\n# confusion matrix - training set\nprint(table(mypredict[1:length(trainData$Diagnosis)], trainData$Diagnosis, dnn =c(\"Actual\",\"Predicted\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Predicted\nActual   0   1\n     0 158   0\n     1   0  97\n```\n\n\n:::\n\n```{.r .cell-code}\n# accuracy(trainData$Diagnosis, mypredict[1:length(trainData$Diagnosis)]) #cross-entropy \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# model evaluation\ntestPred <- neuralnet::compute(nn, testData[,1:22])$net.result\ntestPred <- apply(testPred, c(1), round)\n# confusion matrix - test set\nprint(table(testPred[1:length(testData$Diagnosis)], testData$Diagnosis, dnn =c(\"Actual\", \"Predicted\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Predicted\nActual  0  1\n     0 97  5\n     1  2 56\n```\n\n\n:::\n\n```{.r .cell-code}\n# accuracy(testPred[1:length(testData$Diagnosis)], testData$Diagnosis) #cross-entropy \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# model evaluation\nxvalPred <- neuralnet::compute(nn, xvalData[,1:22])$net.result\nxvalPred <- apply(xvalPred, c(1), round)\n# confusion matrix - xval set\nprint(table(xvalPred[1:length(xvalData$Diagnosis)], xvalData$Diagnosis, dnn =c(\"Actual\", \"Predicted\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Predicted\nActual  0  1\n     0 97  0\n     1  3 54\n```\n\n\n:::\n\n```{.r .cell-code}\n# accuracy(xvalPred[1:length(xvalData$Diagnosis)], xvalData$Diagnosis) #cross-entropy \n```\n:::\n\n\n#### Mean Scores Comparison \n\nObservation & Notes \\| Section **in-progress ...**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn2 <- (mypredict == trainData$Diagnosis)\nn3 <- (testPred == testData$Diagnosis)\nn4 <- (xvalPred == xvalData$Diagnosis)\n\nmean(n2); mean(n3); mean(n4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.95625\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9805195\n```\n\n\n:::\n:::\n\n\n#### ROC Curve\n\nObservation & Notes \\| Section **in-progress ...**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ROC curve analysis \npred <- neuralnet::compute(nn, nn$covariate)$net.result\npredObj <- prediction(pred[1:length(xvalData$Diagnosis)], xvalData$Diagnosis)\nrocObj <- performance(predObj, measure=\"tpr\", x.measure=\"fpr\")\naucObj <- performance(predObj, measure = \"auc\")\nplot(rocObj,  main = \"ROC Curve\", cex.lab=1.25, cex.main = 1.5, col = \"blue\")\ntext(.75, .25, paste(\"Area under the curve:\", round(aucObj@y.values[[1]], 4)),\n     col = \"darkred\", cex = 1.25)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/roc_curve-1.png){width=768}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}