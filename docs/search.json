[
  {
    "objectID": "index.html#welcome-to-my-portfolio",
    "href": "index.html#welcome-to-my-portfolio",
    "title": "Oscar Cardec",
    "section": "",
    "text": "Highly experienced Data Scientist and Machine Learning Engineer with over 20 years of military experience and comprehensive knowledge across data analysis, visualizations, machine learning, deep learning, and Generative AI. Specializing in data pipelines, exploration, data cleaning & analysis, visualization, and modeling; with both structured and unstructured data sources. Expert in developing complex visualizations and leveraging advanced machine learning techniques to solve global challenges. Proven ability to translate complex data insights into actionable information for decision-making in public and private sectors.\n\n\n\nUniversity of Maryland, Global Campus - MS in Data Analytics (MSDA)\nAmerican Military University - BS in Information Technology Management\nCommunity College of the Air Force - AS in Intelligence Studies & Technology\n\n\n\nWTI | R&D, Data Strategist | Jul 2023 - Present\nGovCIO | Data Scientist & ML Specialist | Feb 2023 - Jul 2023\nDeloitte & Touché, LLC | Lead Data Scientist | Apr 2021 - Feb 2023\nAccenture Federal Services | Data Science Intern | Oct 2020 - Mar 2021\nUS Air Force | Manager, Intelligence Analyst | 2013 - 2020\nUS Air Force | Information Manager & Database Administrator | 2007 - 2013\nUS Air Force | Aerospace Maintenance Craftsman | 2000 - 2007"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I am passionate about harnessing the power of data and machine learning to unlock endless possibilities. With a background in military operations and intelligence analysis, I have dedicated my career to transforming raw data into actionable insights that drive innovation and growth.\nThroughout my journey, I have:\n\nTransformed Data into Insight: Leveraged advanced data analytics and machine learning techniques to uncover hidden patterns and trends, leading to strategic decision-making and operational efficiency.\nDriven Innovation: Spearheaded projects that integrate cutting-edge machine learning algorithms to solve complex problems, enhance customer experiences, and optimize processes.\nCollaborated for Success: Worked with cross-functional teams to design and implement data-driven solutions, ensuring seamless integration and maximum impact.\nAchieved Tangible Results: Delivered measurable improvements in key performance indicators, demonstrating the real-world impact of data-driven strategies.\n\nAs a data professional at my current company, I continue to explore the frontiers of data science and machine learning. My mission is to push the boundaries of what’s possible, using data as a catalyst for change and growth.\nWhen I’m not diving into dataframes and algorithms, you can find me reading, hiking or spending quality time with my wife and lovely kiddos; always eager to explore new horizons and build new memories.\nLet’s connect and explore how we can harness the power of data together!\n\nThank you for visiting my portfolio.\n~ OC"
  },
  {
    "objectID": "resume/index.html",
    "href": "resume/index.html",
    "title": "OSCAR CARDEC",
    "section": "",
    "text": "Williamsburg, Virginia\nocmain@gocardec.com\n443.296.2380\n\n\n\nHighly experienced Data Scientist and Machine Learning Engineer with over 20 years of military experience and comprehensive knowledge across data analysis, visualizations, machine learning, deep learning, and Generative AI. Specializing in data pipelines, exploration, cleansing, analysis, visualizations and modeling with both structured and unstructured data sources. Expert in developing complex visualizations and leveraging advanced machine learning techniques to solve global challenges. Proven ability to translate complex data insights into actionable information for decision-making in public and private sectors. Active security clearance and extensive experience supporting Department of Defense clients.\n\n\n\n\nMachine Learning\nGenerative AI\nIntelligence Analysis\nCritical Thinking\nPredictive Modeling\nDecision Analysis\nData Strategist\nContinuous Learner\n\n\n\n\n\n\n• Directed cloud solution research, market analysis, and data migration, ensured operational integrity.\n• Steered Enterprise Data Management Plan review and implementation in support of the ACC & DAF.\n• Developed strategies for data catalog and data governance in line with DoD VAULTIS guidelines.\n• Overhauled ML practices and data mining strategies; standardized decision-making, workflow analysis.\n• Created and optimized data taxonomies/ontologies, and audited cloud capabilities for analytic solutions.\n\n\n\n• Directed machine learning projects, utilizing data mining and anomaly detection to uncover insights.\n• Led quantitative analysis using operations research tools and time-series forecasting.\n• Conducted training on Splunk MLTK and integrated it into daily operations.\n\n\n\n• Spearheaded data analysis for DHS/CBP, optimizing asset allocation through historical data insights.\n• Implemented machine learning models and provided mentoring to junior staff.\n• Developed K-means algorithms for public health initiatives and led analytic proof of concept projects.\n• Advanced analytic practices for ACC/A3 FORGEN, improved data strategy and source ingestion.\n• Conducted social network analysis, topic modeling, and sentiment analysis, advanced analytical practices.\n\n\n\n• Sustained national security operations by employing novel natural language processing (NLP), social media & web content scraping, topic mining, and sentiment analysis techniques.\n• Utilized EDA tradecraft & ML procedures to uncover hidden data, meeting client’s information requests.\n\n\n\n• Managed intelligence collection functions, improving operational capabilities by 85%.\n• Delivered over 1200 intelligence briefs to senior leadership.\n• Directed the allocation and training of 2,600 Intelligence Analysts, enhancing workforce efficiency.\n\n\n\n• Provided critical recommendations, reducing operational errors by 80%.\n• Supervised 1,300 personnel in ISR missions and managed DCGS programs.\n• Led joint teams in foreign missile analysis and multi-source data extraction.\n\n\n\n• Oversaw counterterrorism operations, assessing global targets and cyber objectives.\n• Directed counter-proliferation missions, leading to international sanctions.\n• Coordinated Force Protection across national organizations, ensuring the safe return of personnel.\n\n\n\n\n\n\n• Researched and integrated data support vector machine (SVM) and k-nearest neighbors (KNN) heuristic algorithms to enhance Federal Aviation Administration’s NextGen R&D Office aircraft’s lateral deviation anomaly detection tools.\n• Designed Conditional Inference Tree and Random Forest for classification and interpretation of CTGs, optimizing identification of at-risk newborns and their mothers.\n• Developed an irregular-cells Convolutional Neural Network (CNN) predictive model for early detection of breast carcinoma.\n• Classified Landsat images using K-means model, base-lining image study with vector/centroid pixel- dimension features.\n\n\n\n\n\n\n\n\n\nAWS, Azure, beautifulsoup, C#, caret, datawrapper, docker, dv-api, faker, GCP, geopandas, git, ggmap, gmodels, googlevis, ggvis, graphDB, H2O, IBM cognos analytics, iml, jupyter notebook, keras, korpus, label studio, matplotlib, mobi, mysql, nltk, numpy, oneR, pandas, parallel, plotly, Power BI, protégé, pyspark, Python, pytorch, quanteda, quarto, ranger, R, Rstudio, SAS E-miner, scikit-learn, scipy, scrapy, seaborn, selenium, shiny, simpy, sdv, splunk mltk, spyder, spacy, sql, sqlite3, statsmodels, Tableau, TensorFlow, Tesseract OCR, tidygraph, tidyverse, tm, vip, vs code, xgboost, zoo"
  },
  {
    "objectID": "resume/index.html#professional-summary",
    "href": "resume/index.html#professional-summary",
    "title": "OSCAR CARDEC",
    "section": "",
    "text": "Highly experienced Data Scientist and Machine Learning Engineer with over 20 years of military experience and comprehensive knowledge across data analysis, visualizations, machine learning, deep learning, and Generative AI. Specializing in data pipelines, exploration, cleansing, analysis, visualizations and modeling with both structured and unstructured data sources. Expert in developing complex visualizations and leveraging advanced machine learning techniques to solve global challenges. Proven ability to translate complex data insights into actionable information for decision-making in public and private sectors. Active security clearance and extensive experience supporting Department of Defense clients."
  },
  {
    "objectID": "resume/index.html#core-competencies",
    "href": "resume/index.html#core-competencies",
    "title": "OSCAR CARDEC",
    "section": "",
    "text": "Machine Learning\nGenerative AI\nIntelligence Analysis\nCritical Thinking\nPredictive Modeling\nDecision Analysis\nData Strategist\nContinuous Learner"
  },
  {
    "objectID": "resume/index.html#professional-experience",
    "href": "resume/index.html#professional-experience",
    "title": "OSCAR CARDEC",
    "section": "",
    "text": "• Directed cloud solution research, market analysis, and data migration, ensured operational integrity.\n• Steered Enterprise Data Management Plan review and implementation in support of the ACC & DAF.\n• Developed strategies for data catalog and data governance in line with DoD VAULTIS guidelines.\n• Overhauled ML practices and data mining strategies; standardized decision-making, workflow analysis.\n• Created and optimized data taxonomies/ontologies, and audited cloud capabilities for analytic solutions.\n\n\n\n• Directed machine learning projects, utilizing data mining and anomaly detection to uncover insights.\n• Led quantitative analysis using operations research tools and time-series forecasting.\n• Conducted training on Splunk MLTK and integrated it into daily operations.\n\n\n\n• Spearheaded data analysis for DHS/CBP, optimizing asset allocation through historical data insights.\n• Implemented machine learning models and provided mentoring to junior staff.\n• Developed K-means algorithms for public health initiatives and led analytic proof of concept projects.\n• Advanced analytic practices for ACC/A3 FORGEN, improved data strategy and source ingestion.\n• Conducted social network analysis, topic modeling, and sentiment analysis, advanced analytical practices.\n\n\n\n• Sustained national security operations by employing novel natural language processing (NLP), social media & web content scraping, topic mining, and sentiment analysis techniques.\n• Utilized EDA tradecraft & ML procedures to uncover hidden data, meeting client’s information requests.\n\n\n\n• Managed intelligence collection functions, improving operational capabilities by 85%.\n• Delivered over 1200 intelligence briefs to senior leadership.\n• Directed the allocation and training of 2,600 Intelligence Analysts, enhancing workforce efficiency.\n\n\n\n• Provided critical recommendations, reducing operational errors by 80%.\n• Supervised 1,300 personnel in ISR missions and managed DCGS programs.\n• Led joint teams in foreign missile analysis and multi-source data extraction.\n\n\n\n• Oversaw counterterrorism operations, assessing global targets and cyber objectives.\n• Directed counter-proliferation missions, leading to international sanctions.\n• Coordinated Force Protection across national organizations, ensuring the safe return of personnel."
  },
  {
    "objectID": "resume/index.html#education",
    "href": "resume/index.html#education",
    "title": "OSCAR CARDEC",
    "section": "",
    "text": "• Researched and integrated data support vector machine (SVM) and k-nearest neighbors (KNN) heuristic algorithms to enhance Federal Aviation Administration’s NextGen R&D Office aircraft’s lateral deviation anomaly detection tools.\n• Designed Conditional Inference Tree and Random Forest for classification and interpretation of CTGs, optimizing identification of at-risk newborns and their mothers.\n• Developed an irregular-cells Convolutional Neural Network (CNN) predictive model for early detection of breast carcinoma.\n• Classified Landsat images using K-means model, base-lining image study with vector/centroid pixel- dimension features."
  },
  {
    "objectID": "resume/index.html#technical-competencies",
    "href": "resume/index.html#technical-competencies",
    "title": "OSCAR CARDEC",
    "section": "",
    "text": "AWS, Azure, beautifulsoup, C#, caret, datawrapper, docker, dv-api, faker, GCP, geopandas, git, ggmap, gmodels, googlevis, ggvis, graphDB, H2O, IBM cognos analytics, iml, jupyter notebook, keras, korpus, label studio, matplotlib, mobi, mysql, nltk, numpy, oneR, pandas, parallel, plotly, Power BI, protégé, pyspark, Python, pytorch, quanteda, quarto, ranger, R, Rstudio, SAS E-miner, scikit-learn, scipy, scrapy, seaborn, selenium, shiny, simpy, sdv, splunk mltk, spyder, spacy, sql, sqlite3, statsmodels, Tableau, TensorFlow, Tesseract OCR, tidygraph, tidyverse, tm, vip, vs code, xgboost, zoo"
  },
  {
    "objectID": "blog_index.html",
    "href": "blog_index.html",
    "title": "Projects",
    "section": "",
    "text": "This is a repo of my previously completed assessments and data mining projects. The main idea is to represent career progression and exposure to the broad arena of data analytical theory and methods.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Projects\n\n\n\nnews\n\n\n\n\n\n\n\nOscar Cardec\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConditional Inference Trees\n\n\n\nCTREE\n\n\nDecision Tree\n\n\nClassification\n\n\n\nSupervised learning classifications using the R package partykit conditional inference trees\n\n\n\nOscar Cardec\n\n\nOct 22, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKmeans Clustering\n\n\n\nkmeans\n\n\nclustering\n\n\nclassification\n\n\n\nUnsupervised learning clustering and classification with Kmeans\n\n\n\nOscar Cardec\n\n\nSep 4, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHouse Market Analysis - Regression Model\n\n\n\nregression\n\n\nhousing\n\n\n\n\n\n\n\nOscar Cardec\n\n\nJul 21, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime Series Analysis - AAPL\n\n\n\nTime Series\n\n\nForecast\n\n\n\n\n\n\n\nOscar Cardec\n\n\nJul 15, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeospatial Analysis Infographic\n\n\n\nTablea\n\n\nInfographic\n\n\nGeo\n\n\n\nGDP analysis across Middle East (FY 2020)\n\n\n\nOscar Cardec\n\n\nApr 13, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJoin the Alliance\n\n\n\nInfographic\n\n\nStar Wars\n\n\nTableau\n\n\n\n\n\n\n\nOscar Cardec\n\n\nMar 26, 2020\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/time_series/index.html",
    "href": "posts/time_series/index.html",
    "title": "Time Series Analysis - AAPL",
    "section": "",
    "text": "Time Series Analysis\nThe following is a basic time series analysis of Apple, Inc Stocks market between July 2019 and July 2020.\n\n\nNotice how the limitation of global imports starts to affect the company around Feb 2020. By March of the same year, the company reported loses over $1 Trillion. Nevertheless, in June 10, 2020, Apple became the first U.S. company to reach $1.5 Trillion market cap.\n\nCorrelation between external events, closed price, and total volume.\n\nConsidering the previous 20 periods we can display the linear trend and forecast estimate.\n\nUltimately, all graphics can get organized as an interactive dashboard using Tableau’s capabilities."
  },
  {
    "objectID": "posts/ctree_classifier/index.html",
    "href": "posts/ctree_classifier/index.html",
    "title": "Conditional Inference Trees",
    "section": "",
    "text": "Introduction\nCardiotocograms, also known as CTGs, have been instrumental within clinical medicine for a long time. Obstetricians use these measurements and classifications to obtain detailed information and intelligence about newborns and their mother prior and during labor. In 2018, an article presented through the Journal of Clinical Medicine detailed the practicality of CTG. The same article noted that interpretations of these censorial readings is mainly attributed to the observer; which creates challenges of consistency of interpretations and defies the human naked- eye. Questions like what happens if/when the interpreter misses a key detail, or what could be the meaning of a combination of diagnostic signals, furthermore, what time-sensitive conditions may these measurements expose, requiring immediate actions? These are few examples of concerns posed by the continuous practice of merely optical assessments of a df. (Zhao, Zhang, and Deng 2018)\nThe following exploration presents an assessment of CTGs using the conditional inference tree (ctree) model. The same shows how the algorithm expedites and enhances the interpretation of CTG readings while appraising multiple fetal readings simultaneously. Moreover, the study aims to identify potential hidden patters which may require further attention.\nData\nThe analyzed data comes for the UCI Machine Learning Repository(D. Campos 2000), and it consists of measurements of fetal heart rate (FHR) and other important characteristics as identified and recorded within each cardiotocograms. Ultimately, all CTGs were classified by three subject matter experts, and under unanimity, assigned with response-labels based on the fetal state and/or morphological detected patterns. The following is a list of the variables meaning according to the UCI repository:\n\nLB - FHR baseline (beats per minute)\nAC - # of accelerations per second\nFM - # of fetal movements per second\nUC - # of uterine contractions per second\nDL - # of light decelerations per second\nDS - # of severe decelerations per second\nDP - # of prolonged decelerations per second\nASTV - percentage of time with abnormal short term variability\nMSTV - mean value of short term variability\nALTV - percentage of time with abnormal long term variability\nMLTV - mean value of long term variability Width - width of FHR histogram\nMin - minimum of FHR histogram\nMax - Maximum of FHR histogram\nNmax - # of histogram peaks\nNzeros - # of histogram zeros\nMode - histogram mode\nMean - histogram mean\nMedian - histogram median\nVariance - histogram variance\nTendency - histogram tendency\nCLASS - FHR pattern class code (1 to 10)\nNSP - fetal state class code (N=normal; S=suspect; P=pathologic)\nEDA\nDuring exploratory data analysis the data is confirmed as a combination of 2126 observations and 23 variables. The following is a preview of the first six observations after been ingested as as_tibble.\n\ndf&lt;-as_tibble(read.csv(file=\"cardiotocography.csv\", head=TRUE, sep=\",\", as.is=FALSE))\nprint(df, n=6)\n\n# A tibble: 2,126 × 23\n     LB    AC    FM    UC    DL    DS    DP  ASTV  MSTV  ALTV  MLTV Width   Min\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1   120 0         0 0     0         0 0        73   0.5    43   2.4    64    62\n2   132 0.006     0 0.006 0.003     0 0        17   2.1     0  10.4   130    68\n3   133 0.003     0 0.008 0.003     0 0        16   2.1     0  13.4   130    68\n4   134 0.003     0 0.008 0.003     0 0        16   2.4     0  23     117    53\n5   132 0.007     0 0.008 0         0 0        16   2.4     0  19.9   117    53\n6   134 0.001     0 0.01  0.009     0 0.002    26   5.9     0   0     150    50\n# ℹ 2,120 more rows\n# ℹ 10 more variables: Max &lt;int&gt;, Nmax &lt;int&gt;, Nzeros &lt;int&gt;, Mode &lt;int&gt;,\n#   Mean &lt;int&gt;, Median &lt;int&gt;, Variance &lt;int&gt;, Tendency &lt;int&gt;, CLASS &lt;int&gt;,\n#   NSP &lt;int&gt;\n\n\nThe following code chunks portray a basic assessment of specific attributes and areas of importance such as variability of observations, presence of missing values, mean, standard deviation,\n\n# How much variability the main predictor shows? \nlbx &lt;- IQR(df$LB)\nsummary(df$LB)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  106.0   126.0   133.0   133.3   140.0   160.0 \n\n\nNote: LB attribute’s IQR equals 14, which is significantly small indicating a most values to be clustered around the middle. The following histogram confirms the small IQR.\n\nhist(df$LB, breaks = 12, main=\"Histogram of FHR Baseline\", xlab=\"(beats per minute)\",\n     border=\"darkblue\",col =\"lightgrey\", labels = F)\n\n\n\n\n\n\n\n\n# Are there any missing values present?\ncolSums(is.na(df))\n\n      LB       AC       FM       UC       DL       DS       DP     ASTV \n       0        0        0        0        0        0        0        0 \n    MSTV     ALTV     MLTV    Width      Min      Max     Nmax   Nzeros \n       0        0        0        0        0        0        0        0 \n    Mode     Mean   Median Variance Tendency    CLASS      NSP \n       0        0        0        0        0        0        0 \n\n\n\nt.test(df$LB)\n\n\n    One Sample t-test\n\ndata:  df$LB\nt = 624.59, df = 2125, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 132.8853 133.7224\nsample estimates:\nmean of x \n 133.3039 \n\n\n\n# LB stats\nm&lt;-mean(df$LB)\nstd&lt;-sd(df$LB)\nupr=m+std\nlwr=m-std\nlbdf &lt;- data.frame(df,my_x = 0 + rnorm(length(df$LB),\n        mean=m, sd=std),my_y = 0 + rnorm(length(df$LB), mean=m, sd=std))\n# LB Variation\nprint(pltlb &lt;- ggplot(lbdf, xlab = F, aes(x=(my_x), y=my_y)) + \n        geom_line(col=\"grey51\",linemitre=1) +\n        geom_smooth(method=lm , color=\"blue\", lty=3, fill=\"light blue\", se=T) +\n        labs(x=NULL, y=\"BPM\", title=\"FHR LB Variation\\nIn Relation To The Mean\")+\n        theme_ipsum())\n\n\n\n\n\n\n\n\n# very first graph representation with manual boundary calculations\nupr2=m+(std*2)\nlwr2=m-(std*2)\n# Plot LB distribution boundaries \nplot.new()\nplot(df$LB, type=\"l\", col=\"grey51\", ylab=\"LB\", main=\"1 & 2 Standard Deviations\")\nabline(h = m, col = \"blue\")\nabline(h = upr, col = \"orange\", lty=2)\nabline(h = lwr, col = \"orange\", lty=2)\nabline(h = upr2, col = \"red\", lty=2)\nabline(h = lwr2, col = \"red\", lty=2)\ntext(-65,134, \"mean:133.30\", col = \"blue\", adj = c(0, -.1))\ntext(-65,upr, round(upr, 2), col = \"black\", adj = c(0, -.1))\ntext(-65,lwr, round(lwr, 2), col = \"black\", adj = c(0, -.1))\ntext(-65,upr2, round(upr2, 2), col = \"black\", adj = c(0, -.1))\ntext(-65,lwr2, round(lwr2, 2), col = \"black\", adj = c(0, -.1))\n\n\n\n\n\n\n# LB Observations higher than 2-s.d.\n lba&lt;-(sum(df$LB &gt;152.99)) #39\n# LB Observations lower than 2-s.d.\n lbb&lt;-(sum(df$LB &lt;113.62)) #44\n lba+lbb #=83 obs outside of 2-s.d.\n\n[1] 83\n\nsum(between(df$LB, 113.62, 152.99))/nrow(df) # of obs within 2-s.d.\n\n[1] 0.9609595\n\n\n\n# Exclude non-original measurements, rename targeted values\ndf[12:22] &lt;- NULL\ndf$NSP&lt;-as.numeric(df$NSP)\n# enumeration of labels with the factor function\ndf$NSP&lt;-factor(df$NSP, levels= 1:3, labels = c(\"Normal\",\"Suspect\", \"Pathologic\"))\n\n\n# Visualization of original NSP\nplot(df$NSP, main=\"Original NSP Distribution\",\n     xlab=\"Fetal State Classification\", \n     ylab=\"Frequency\", col=c(3, 7, 2))\ntext(df$NSP, labels=as.character(tabulate(df$NSP)), adj=3, pos=3)\n\n\n\n\n\n\n\n\n# additional way to preview distribution of attributes\n# distributions preview\ndf[,1:12] %&gt;%\n  gather() %&gt;%\n  ggplot(aes(value)) +\n  theme_light() + labs( title=\"FHR Measurement Distributions\")+\n  theme(axis.text.x = element_text(angle=90)) +\n  facet_wrap(~ key, scales = \"free\", shrink = TRUE) +\n  geom_bar(mapping = aes(value),\n           color=\"darkblue\", fill=\"lightgrey\")\n\n\n\n\n\n\n\nIn progress …\n\n# Summary of DF after encoding the label vector as numbers. \nsummary(df)\n\n       LB              AC                 FM                 UC          \n Min.   :106.0   Min.   :0.000000   Min.   :0.000000   Min.   :0.000000  \n 1st Qu.:126.0   1st Qu.:0.000000   1st Qu.:0.000000   1st Qu.:0.002000  \n Median :133.0   Median :0.002000   Median :0.000000   Median :0.004000  \n Mean   :133.3   Mean   :0.003178   Mean   :0.009481   Mean   :0.004366  \n 3rd Qu.:140.0   3rd Qu.:0.006000   3rd Qu.:0.003000   3rd Qu.:0.007000  \n Max.   :160.0   Max.   :0.019000   Max.   :0.481000   Max.   :0.015000  \n       DL                 DS                  DP                 ASTV      \n Min.   :0.000000   Min.   :0.000e+00   Min.   :0.0000000   Min.   :12.00  \n 1st Qu.:0.000000   1st Qu.:0.000e+00   1st Qu.:0.0000000   1st Qu.:32.00  \n Median :0.000000   Median :0.000e+00   Median :0.0000000   Median :49.00  \n Mean   :0.001889   Mean   :3.293e-06   Mean   :0.0001585   Mean   :46.99  \n 3rd Qu.:0.003000   3rd Qu.:0.000e+00   3rd Qu.:0.0000000   3rd Qu.:61.00  \n Max.   :0.015000   Max.   :1.000e-03   Max.   :0.0050000   Max.   :87.00  \n      MSTV            ALTV             MLTV                NSP      \n Min.   :0.200   Min.   : 0.000   Min.   : 0.000   Normal    :1655  \n 1st Qu.:0.700   1st Qu.: 0.000   1st Qu.: 4.600   Suspect   : 295  \n Median :1.200   Median : 0.000   Median : 7.400   Pathologic: 176  \n Mean   :1.333   Mean   : 9.847   Mean   : 8.188                    \n 3rd Qu.:1.700   3rd Qu.:11.000   3rd Qu.:10.800                    \n Max.   :7.000   Max.   :91.000   Max.   :50.700                    \n\n\n\n# split the data into a training and test sets\nset.seed(1234)\nind &lt;- sample(2, nrow(df), replace = T, prob = c(0.70, 0.30))\ntrain.data &lt;- df[ind == 1, ]\ntest.data &lt;- df[ind == 2, ]\n\n#run the method on a training data\nmyFormula&lt;-NSP~.\nmodel &lt;- ctree(myFormula, data = train.data)\n\n\n# output the tree structure\n# print(model)\nmodel[4]\n\n\nModel formula:\nNSP ~ LB + AC + FM + UC + DL + DS + DP + ASTV + MSTV + ALTV + \n    MLTV\n\nFitted party:\n[4] root\n|   [5] ASTV &lt;= 73\n|   |   [6] DL &lt;= 0.008\n|   |   |   [7] DP &lt;= 0\n|   |   |   |   [8] LB &lt;= 149\n|   |   |   |   |   [9] AC &lt;= 0.001\n|   |   |   |   |   |   [10] UC &lt;= 0: Normal (n = 34, err = 14.7%)\n|   |   |   |   |   |   [11] UC &gt; 0: Normal (n = 231, err = 3.5%)\n|   |   |   |   |   [12] AC &gt; 0.001: Normal (n = 626, err = 0.3%)\n|   |   |   |   [13] LB &gt; 149: Normal (n = 17, err = 35.3%)\n|   |   |   [14] DP &gt; 0\n|   |   |   |   [15] MLTV &lt;= 0.9: Normal (n = 7, err = 28.6%)\n|   |   |   |   [16] MLTV &gt; 0.9\n|   |   |   |   |   [17] MLTV &lt;= 8.8: Normal (n = 28, err = 0.0%)\n|   |   |   |   |   [18] MLTV &gt; 8.8: Normal (n = 7, err = 28.6%)\n|   |   [19] DL &gt; 0.008\n|   |   |   [20] ASTV &lt;= 58: Normal (n = 35, err = 0.0%)\n|   |   |   [21] ASTV &gt; 58: Pathologic (n = 25, err = 40.0%)\n|   [22] ASTV &gt; 73: Pathologic (n = 11, err = 45.5%)\n\nNumber of inner nodes:     9\nNumber of terminal nodes: 10\n\n\n\n#8. visualize the tree\n# plot(model, main=\"Cardiotocography Data\\n Conditional Inference Tree\\n'Extended'\",\n#       type=\"simple\",ep_args = list(justmin = 8), drop_terminal = F, \n#      gp = gpar(fontsize = 9), margins = c(4,4, 4, 4))\n\nplot(model, type=\"extended\", ep_args = list(justmin =8), drop_terminal=F, tnex=1.5, \n     gp=gpar(fontsize = 8, col=\"dark blue\"),\n     inner_panel = node_inner(model, fill=c(\"light grey\",\"cyan\"), pval=T), \n     terminal_panel=node_barplot(model, fill=c(3,7,2), beside=T, ymax=1, rot = 45, \n     just = c(.95,.5), ylines=F, widths = 1, gap=0.05, reverse=F, id=T), \n     margins = c(3,0, 3, 0),\n     main =\"Cardiotocography Data\\n Conditional Inference Tree\\n'Extended'\")\n\n\n\n\n\n\n\n\n#9. Confusion matrix\ntable(predict(model), train.data$NSP, dnn=c(\"PREDICTED\", \"ACTUAL\"))\n\n            ACTUAL\nPREDICTED    Normal Suspect Pathologic\n  Normal       1168      70          4\n  Suspect        10     123          1\n  Pathologic     17       8        122\n\n# predicted classification accuracy with training data\nsum(predict(model) == train.data$NSP)/length(train.data$NSP)\n\n[1] 0.9277741\n\nprop.table(table(predict(model), train.data$NSP, dnn=c(\"PREDICTED\", \"ACTUAL\")))\n\n            ACTUAL\nPREDICTED          Normal      Suspect   Pathologic\n  Normal     0.7669074196 0.0459619173 0.0026263953\n  Suspect    0.0065659882 0.0807616546 0.0006565988\n  Pathologic 0.0111621799 0.0052527905 0.0801050558\n\n\n\n#10. Evaluate the model on a test data\nmodel2 &lt;- ctree(myFormula, data = test.data)\nmodel2[4]\n\n\nModel formula:\nNSP ~ LB + AC + FM + UC + DL + DS + DP + ASTV + MSTV + ALTV + \n    MLTV\n\nFitted party:\n[4] root\n|   [5] DP &lt;= 0\n|   |   [6] DL &lt;= 0.01\n|   |   |   [7] ALTV &lt;= 1: Normal (n = 291, err = 1.0%)\n|   |   |   [8] ALTV &gt; 1\n|   |   |   |   [9] LB &lt;= 143\n|   |   |   |   |   [10] ASTV &lt;= 59: Normal (n = 78, err = 0.0%)\n|   |   |   |   |   [11] ASTV &gt; 59: Normal (n = 14, err = 42.9%)\n|   |   |   |   [12] LB &gt; 143\n|   |   |   |   |   [13] ASTV &lt;= 45: Normal (n = 7, err = 14.3%)\n|   |   |   |   |   [14] ASTV &gt; 45: Suspect (n = 13, err = 15.4%)\n|   |   [15] DL &gt; 0.01: Normal (n = 10, err = 30.0%)\n|   [16] DP &gt; 0\n|   |   [17] MSTV &lt;= 1.7: Normal (n = 12, err = 25.0%)\n|   |   [18] MSTV &gt; 1.7: Normal (n = 12, err = 50.0%)\n\nNumber of inner nodes:    7\nNumber of terminal nodes: 8\n\n\n\n# plot(model2, main=\"Cardiotocography Data\\n Simple Conditional Inference Tree\\nby ocardec\",\n#      type=\"simple\",ep_args = list(justmin = 10), drop_terminal = F, gp = gpar(fontsize = 12))\n\nplot(model2, ep_args = list(justmin = 8), type=\"extended\", drop_terminal = F, \n     tnex=1, gp= gpar(fontsize = 8, col=\"dark blue\"), \n     inner_panel = node_inner (model2, fill=c(\"lightgrey\",\"yellow\"), pval=T, id=T),\n     terminal_panel=node_barplot(model2, col=\"black\", fill=c(3,7,2, 0.3), beside=T, \n     ymax=1, rot = 45, just = c(\"right\", \"top\"), ylines=F, \n     widths=1, gap=0.1, reverse=F, id=F), margins = c(3, 0, 3, 0), \n     main=\"Cardiotocography Data\\n Extended Conditional Inference Tree\\nby ocardec\")\n\n\n\n\n\n\n\n\n# Confusion matrix and stats\ntestPred2 &lt;- predict(model2, newdata = test.data, method=\"NSP\")\nconfusionMatrix(testPred2, test.data$NSP)\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   Normal Suspect Pathologic\n  Normal        449      21         12\n  Suspect         9      73          4\n  Pathologic      2       0         33\n\nOverall Statistics\n                                          \n               Accuracy : 0.9204          \n                 95% CI : (0.8958, 0.9407)\n    No Information Rate : 0.7629          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7809          \n                                          \n Mcnemar's Test P-Value : 0.001165        \n\nStatistics by Class:\n\n                     Class: Normal Class: Suspect Class: Pathologic\nSensitivity                 0.9761         0.7766           0.67347\nSpecificity                 0.7692         0.9745           0.99639\nPos Pred Value              0.9315         0.8488           0.94286\nNeg Pred Value              0.9091         0.9594           0.97183\nPrevalence                  0.7629         0.1559           0.08126\nDetection Rate              0.7446         0.1211           0.05473\nDetection Prevalence        0.7993         0.1426           0.05804\nBalanced Accuracy           0.8727         0.8755           0.83493\n\n\n\n\n\nReferences\n\nD. Campos, J. Bernardes. 2000. “Cardiotocography.” UCI Machine Learning Repository. https://doi.org/10.24432/C51S4N.\n\n\nZhao, Zhidong, Yang Zhang, and Yanjun Deng. 2018. “A Comprehensive Feature Analysis of the Fetal Heart Rate Signal for the Intelligent Assessment of Fetal State.” Journal of Clinical Medicine 7 (8): 223. https://doi.org/10.3390/jcm7080223."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Projects",
    "section": "",
    "text": "Welcome to my projects!\n\nThis is my first post, it’s my hope you enjoy the content of this portfolio and learn learn something new from my posts. Please reach back and feel free to provide some constructive feedback.\nLet’s connect."
  },
  {
    "objectID": "posts/geo_analysis_infograph/index.html",
    "href": "posts/geo_analysis_infograph/index.html",
    "title": "Geospatial Analysis Infographic",
    "section": "",
    "text": "Geospatial Infographic\nThe main objective of this visual is to explore relationships and potential patterns between economic prosperity and possible quality of life across the included countries. This could be the beginning of deeper assessments to contain: economic disparities, policy and decision making, international relationships, health care, income distribution, and more.\n\n\n\n\n\n\nData source: World Bank Group"
  },
  {
    "objectID": "posts/join_alliance_infograph/index.html",
    "href": "posts/join_alliance_infograph/index.html",
    "title": "Join the Alliance",
    "section": "",
    "text": "Infographic\nBy definition, an infographic is a visual representation of information, data, or knowledge intended to present complex information, quickly, and clearly. It combines graphics, text, and data to communicate a message, explain a concept or show data patterns and relationships.\n\n\n\n\n\n\nData source: Kaggle"
  },
  {
    "objectID": "resources/index.html",
    "href": "resources/index.html",
    "title": "Recommended Resources",
    "section": "",
    "text": "Web Sites\n\n\nThe Algorithms\nData Science Resource Hub - SAS\nData Science Central\nData, AI & Machine Learning\nStorytelling with Data\n\n\n\nCourses\n\n\nIntroduction to Data Science | edx IBM\nThe Data Scientist’s Toolbox\nAnalyze Data with Pandas\nProfessional Certificate in Data Science | edx Harvard\nApplied Data Science Program: Leveraging AI for Effective Decision-Making | MiT\nDeep Learning | Deeplizard\nDeep Learning Toolbox | MathWorks\n\n\n\nProjects & Books\n\n\nBig Book of R\nData Science on the GCP\n100+ Python projects\nR Books Collection\n40+ Modern ML Tutorials\n\n\n\nVisualization Package/Libraries\n\n\nmatplotlib\nggplot2\nseaborn\nGoogle Charts\nGrafana\nDatawrapper\nVisual Cinnamon\n\n\n\nBI Tools & Platforms\n\n\nKNIME\nSAS Enterprise Miner\nIBM Cognos Analytics\nSplunk MLTK\nShiny\nMode\nOSF\nQuarto\nRStudio\nAnaconda\nOrange\nSpyder\nJupyter\n\n\n\nCommunity\n\n\nData Science Hangout by Posit\nThe Data Canteen by Ted Hallum\nData Humans Podcast by Libby Heeren\nData Science Leaders Podcast by Kjell Carlsson\nData Skeptic Podcast by Kyle Polich\nSuper Data Science Podcast by Jon Krohn\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "books/index.html",
    "href": "books/index.html",
    "title": "Recommended Books",
    "section": "",
    "text": "“Our job is obvious: We need to get out of the way, shine a light, and empower a new generation to teach itself and to go further and faster than any generation ever has.”\n~ Seth Godin\n\n\n\n\n\nApplied Predictive Modeling by Kuhn, Max, & Johnson, Kjell\n\n\nDesigning Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems by Martin Kleppmann\n\n\n\nPractical Simulations for Machine Learning: Using Synthetic Data for AI by by Paris Buttfield-Addison, Mars Buttfield-Addison, Tim Nugent, & Jon Manning\n\n\nAdvanced R, Second Edition (Chapman & Hall/CRC The R Series) by Hadley Wickham\n\n\n\nDeep Learning (Adaptive Computation and Machine Learning Series) by Ian Goodfellow, Yoshua Bengio, & Aaron Courville\n\n\nData Engineering with Python: Work with massive datasets to design data models and automate data pipelines using Python by Paul Crickard\n\n\n\nPractical Statistics for Data Science: 50 Essential Concepts by Peter Bruce, & Andrew Bruce\n\n\nAn Introduction to Statistical Learning: with Applications in R by Gareth James, Daniela Witten, Trevor Hastie, & Robert Tibshirani\n\n\n\nThe Hundred-Page Machine Learning Book by Andriy Burkov\n\n\nMachine Learning Engineering by Andriy Burkov\n\n\n\nData Science from Scratch: First Principles with Python by Joel Grus\n\n\nHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems\n\n\n\nData Science Projects with Python: A case study approach to gaining valuable insights from real data with machine learning, 2nd Edition by Stephen Klosterman\n\n\nThe Art of R Programming: A Tour of Statistical Software Design by Norman Matloft\n\n\n\nData Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking by Foster Provost & Tom Fawcett\n\n\nApplied Predictive Analytics: Principles and Techniques for the Professional Data Analyst by Dean Abbott\n\n\n\nA General Introduction to Data Analytics by João Moreira, Andre Carvalho, & Tomás Horvath\n\n\nData Science and Big Data Analytics: Discovering, Analyzing, Visualizing, and Presenting Data by EMC Education Services\n\n\n\nDecision Management Systems: A Practical Guide to Using Business Rules and Predictive Analytics by James Taylor\n\n\nSystems Analysis and Design Shelly Cashman by Scott Tilley & Harry Rosenblatt\n\n\n\nStorytelling with Data: A Data Visualization Guide for Business Professionals by Cole Nussbaumer Knaflic\n\n\nLearn Python 3 the Hard Way: A Very Simple Introduction to the Terrifying Beautiful World of Computer and Code by Zed Shaw\n\n\n\nPython for Data Analysis: Data Wrangling with Pandas, Numpy, and IPython by William McKinney\n\n\nR For Data Science: Import, Tidy, Transform, Visualize, and Model Data by Garrett Grolemund & Hadley Wickham\n\n\n\nMastering Shiny: Build Interactive Apps, Reports, and Dashboards Powered by R\n\n\nThe Proximity Principle: The Proven Strategy That Will Lead to a Career You Love\n\n\n\nSpark: The Definitive Guide: Big Data Processing Made Simple\n\n\nBuild a Career in Data Science\n\n\n\nHands-On Data Analysis with Pandas: A handbook for data collection, wrangling, analysis, and visualization\n\n\nHandbook of Parametric and Nonparametric Statistical Procedures, Fifth Edition\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "reports/index.html",
    "href": "reports/index.html",
    "title": "Reports",
    "section": "",
    "text": "It appears you don't have a PDF plugin for this browser.\n    \n    No biggie... you can click here to\n    download the PDF file."
  },
  {
    "objectID": "posts/kmeans_clustering/index.html",
    "href": "posts/kmeans_clustering/index.html",
    "title": "Kmeans Clustering",
    "section": "",
    "text": "Report in-progress …"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Oscar Cardec",
    "section": "",
    "text": "Highly experienced Data Scientist and Machine Learning Engineer with over 20 years of military experience and comprehensive knowledge across data analysis, visualizations, machine learning, deep learning, and Generative AI. Specializing in data pipelines, exploration, data cleaning & analysis, visualization, and modeling; with both structured and unstructured data sources. Expert in developing complex visualizations and leveraging advanced machine learning techniques to solve global challenges. Proven ability to translate complex data insights into actionable information for decision-making in public and private sectors.\n\n\n\nUniversity of Maryland, Global Campus - MS in Data Analytics (MSDA)\nAmerican Military University - BS in Information Technology Management\nCommunity College of the Air Force - AS in Intelligence Studies & Technology\n\n\n\nWTI | R&D, Data Strategist | Jul 2023 - Present\nGovCIO | Data Scientist & ML Specialist | Feb 2023 - Jul 2023\nDeloitte & Touché, LLC | Lead Data Scientist | Apr 2021 - Feb 2023\nAccenture Federal Services | Data Science Intern | Oct 2020 - Mar 2021\nUS Air Force | Manager, Intelligence Analyst | 2013 - 2020\nUS Air Force | Information Manager & Database Administrator | 2007 - 2013\nUS Air Force | Aerospace Maintenance Craftsman | 2000 - 2007"
  },
  {
    "objectID": "posts/house_market_analysis/index.html",
    "href": "posts/house_market_analysis/index.html",
    "title": "",
    "section": "",
    "text": "Report in progress …"
  }
]